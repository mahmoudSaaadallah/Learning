# awk Command
- TheÂ `awk`Â command is a powerful text processing tool in Linux/Unix, often referred to as a "pattern scanning and processing language."
- It's designed for extracting and manipulating data from text files or standard input, especially when the data is structured into records (lines) and fields (words).

- `awk`Â reads input line by line, and for each line, it attempts to match a specified pattern. If a line matches the pattern,Â `awk`Â performs a corresponding action. If no pattern is specified, the action is performed on every line.

### Basic Structure ofÂ `awk`

The general syntax forÂ `awk`Â is:  
```bash
awk 'pattern { action }' [filename...]
```

- **`pattern`**: A regular expression or a conditional expression that determines which lines the action should apply to. If omitted, the action applies to all lines.
- **`action`**: A series of commands enclosed in curly bracesÂ `{}`Â thatÂ `awk`Â executes when a line matches the pattern. If omitted,Â `awk`Â prints the entire line.
- **`filename...`**: One or more input files. If no files are specified,Â `awk`Â reads from standard input.


### Key Concepts

1. **Records and Fields:**
    - `awk`Â processes input oneÂ **record**Â at a time. By default, a record is a single line.
    - Each record is divided intoÂ **fields**. By default, fields are separated by whitespace (spaces, tabs).
    - `$0`Â refers to the entire current record (the whole line).
    - `$1`,Â `$2`,Â `$3`, etc., refer to the first, second, third, and subsequent fields of the current record.

2. **Field Separator (`FS`)**:  
    You can change the field separator using theÂ `-F`Â option or by setting theÂ `FS`Â built-in variable.

3. **Built-in Variables**:  
    `awk`Â provides several useful built-in variables:
    
    - `NR`: Number of the current record (line number).
    - `NF`: Number of fields in the current record.
    - `RS`: Record Separator (default is newline).
    - `FS`: Field Separator (default is whitespace).
    - `OFS`: Output Field Separator (default is space).
    - `ORS`: Output Record Separator (default is newline).
    - `FILENAME`: Name of the current input file.

4. **Special Patterns (`BEGIN`Â andÂ `END`)**:
    
    - **`BEGIN { action }`**: The action specified here is executedÂ _once_Â beforeÂ `awk`Â starts processing any input lines. This is useful for setting variables, printing headers, etc.
    - **`END { action }`**: The action specified here is executedÂ _once_Â afterÂ `awk`Â has finished processing all input lines. Useful for printing summaries, totals, etc.


----
### Examples (Using Shell Multi-line Input and Script Files)

- **Getting all the content of the passwd file:**
```bash
awk '{print $0}' /etc/passwd
```

---> The output will be exactly like the `cat` command.
```bash
cat /etc/passwd
```

- As we know that the `/etc/passwd` file contains the users for our system and consist of seven fields (loginName, password, UID, GID, Comment, Homer Dir, Shell).
- Now if we want to get the userName we could use `awk` with the `$1` to get the first field.
```bash
# If we use awk '{print $1}' /etc/passwd it will return wrond answer why??
# Because the default seperator is blank(space)(tab), but in the /etc/passwd file the seperator is clone(:).
# So we have to change the default seperator using option -F
awk -F: '{print $1}' /etc/passwd
```


---> option `-F:` means change the separator to be clone.

----

Let's create a sample data file namedÂ `data.txt`Â for our examples:

```bash
Name,Age,City,Occupation,Salary
Alice,30,New York,Engineer,75000
Bob,24,London,Designer,60000
Charlie,35,Paris,Doctor,90000
David,29,New York,Engineer,80000
Eve,42,London,Manager,110000
Frank,28,Berlin,Developer,70000
```

---

#### Example 1: Print Specific Fields (Default Field Separator)

Let's say we have a fileÂ `names.txt`Â with names and ages separated by spaces:

```
John 30
Jane 25
Mike 40
```

**Goal:**Â Print only the names.
**Shell Command:**

```bash
awk '{ print $1 }' names.txt
```

**Output:**

```
John
Jane
Mike
```

---

#### Example 2: Print Specific Fields with a Custom Field Separator

Using ourÂ `data.txt`Â file, where fields are comma-separated.

**Goal:**Â Print the Name and Salary for each person.

**Shell Command:**

```bash
awk -F',' '{ print "Name: " $1 ", Salary: " $5 }' data.txt
```

- `-F','`Â sets the field separator to a comma.
- `$1`Â is the Name,Â `$5`Â is the Salary.

**Output:**

```
Name: Name, Salary: Salary
Name: Alice, Salary: 75000
Name: Bob, Salary: 60000
Name: Charlie, Salary: 90000
Name: David, Salary: 80000
Name: Eve, Salary: 110000
Name: Frank, Salary: 70000
```

Notice the header line is also processed. We'll address that next.

---

#### Example 3: Skip Header and Print Formatted Output

**Goal:**Â Print Name, City, and Occupation for all recordsÂ _except_Â the header, with a custom output format.

**Shell Command (Multi-line):**

```bash
awk -F',' '
NR == 1 { next } # Skip the first line (header)
{
    print "Person: " $1 " lives in " $3 " and works as a " $4 "."
}' data.txt
```

- `NR` refers to the Number Record(line number).
- `NR == 1 { next }`: If the current record number (`NR`) is 1, skip to the next record.
- `print ...`: Prints the formatted string using fieldsÂ `$1`,Â `$3`, andÂ `$4`.

**Output:**

```
Person: Alice lives in New York and works as a Engineer.
Person: Bob lives in London and works as a Designer.
Person: Charlie lives in Paris and works as a Doctor.
Person: David lives in New York and works as a Engineer.
Person: Eve lives in London and works as a Manager.
Person: Frank lives in Berlin and works as a Developer.
```

---
#### Skip the lines that the UserName is root:
```bash
awk -F: '$1=="root" {next} {print $0}' /etc/passwd
```

- `$1=="root" {next}` If the first filed is the root skip and go to the next.
- `print $0` print the current line.

---
#### Example 4: Conditional Printing (UsingÂ `if`Â statements)

**Goal:**Â Find all engineers and print their name and city.

**Shell Command (Multi-line):**

```bash
awk -F',' '
NR == 1 { next }
$4 == "Engineer" {
    print $1 " is an Engineer in " $3 "."
}' data.txt
```

- `$4 == "Engineer"`: This is the pattern. The action will only execute if the fourth field is exactly "Engineer".

**Output:**

```
Alice is an Engineer in New York.
David is an Engineer in New York.
```

---

#### Example 5: Calculate Sum and Average (UsingÂ `BEGIN`Â andÂ `END`)

**Goal:**Â Calculate the total and average salary fromÂ `data.txt`.

**Shell Command (Multi-line):**

```bash
awk -F',' '
BEGIN {
    total_salary = 0;
    count = 0;
    print "--- Salary Report ---"
}
NR == 1 { next } # Skip header
{
    total_salary += $5; # Add salary to total
    count++;            # Increment count
}
END {
    print "Total Salary: " total_salary
    print "Average Salary: " total_salary / count
    print "--- End Report ---"
}' data.txt
```

- `BEGIN`: InitializesÂ `total_salary`Â andÂ `count`, and prints a header.
- `total_salary += $5`: Adds the value of the 5th field (salary) toÂ `total_salary`.Â `awk`Â automatically treats fields as numbers when used in arithmetic operations.
- `END`: Prints the calculated total and average.

**Output:**

```
--- Salary Report ---
Total Salary: 485000
Average Salary: 80833.3
--- End Report ---
```

---

#### Example 6: UsingÂ `awk`Â with a Script File

For more complexÂ `awk`Â programs, it's better to put the script in a separate file.

Let's create a file namedÂ `process_data.awk`:

```bash
# process_data.awk
# This script processes data.txt to categorize people by age and city.

BEGIN {
    FS = ","; # Set field separator
    print "--- Detailed Employee Report ---";
    print "Name        | Age | City      | Occupation | Salary";
    print "------------|-----|-----------|------------|-------";
}

NR == 1 { next } # Skip header line

# Process each data line
{
    printf "%-12s| %-3s | %-9s | %-10s | %-6s\n", $1, $2, $3, $4, $5;

    # Conditional logic based on age
    if ($2 < 30) {
        print "  (Young professional)";
    } else if ($2 >= 30 && $2 < 40) {
        print "  (Mid-career professional)";
    } else {
        print "  (Experienced professional)";
    }

    # Conditional logic based on city
    if ($3 == "New York") {
        print "  (Based in NYC)";
    } else if ($3 == "London") {
        print "  (Based in London)";
    }
    print ""; # Add an empty line for readability
}

END {
    print "--- Report End ---";
}
```

**Shell Command to run the script:**

```bash
awk -f process_data.awk data.txt
```

- `-f process_data.awk`: TellsÂ `awk`Â to read its script from the fileÂ `process_data.awk`.

**Output:**

```
--- Detailed Employee Report ---
Name        | Age | City      | Occupation | Salary
------------|-----|-----------|------------|-------
Alice       | 30  | New York  | Engineer   | 75000 
  (Mid-career professional)
  (Based in NYC)

Bob         | 24  | London    | Designer   | 60000 
  (Young professional)
  (Based in London)

Charlie     | 35  | Paris     | Doctor     | 90000 
  (Mid-career professional)

David       | 29  | New York  | Engineer   | 80000 
  (Young professional)
  (Based in NYC)

Eve         | 42  | London    | Manager    | 110000
  (Experienced professional)
  (Based in London)

Frank       | 28  | Berlin    | Developer  | 70000 
  (Young professional)

--- Report End ---
```

---

#### Example 7: Using Loops (`for`Â loop)

**Goal:**Â Print all fields of each line, prefixed with their field number.

**Shell Command (Multi-line):**

```bash
awk -F',' '
NR == 1 { next }
{
    print "Line " NR ":"
    for (i = 1; i <= NF; i++) {
        print "  Field " i ": " $i
    }
    print "" # Empty line for separation
}' data.txt
```

- `for (i = 1; i <= NF; i++)`: Loops from the first field (`i=1`) up to the total number of fields (`NF`).

**Output:**

```
Line 2:
  Field 1: Alice
  Field 2: 30
  Field 3: New York
  Field 4: Engineer
  Field 5: 75000

Line 3:
  Field 1: Bob
  Field 2: 24
  Field 3: London
  Field 4: Designer
  Field 5: 60000

... (and so on for other lines)
```


#### Using Loops (`for`Â loop)
- What about getting all the userName from /etc/passwd file numbered with the line number.
```bash
awk -F: 'BEGIN{counter = 0}
{for(i = 1; i <= NF; i++)
	{if(i==1)
		{print counter " : " $i; counter++} 
	else {break}}}' /etc/passwd
```

##### ðŸ” Explanation:
- `-F:` â†’ sets colon as the field separator
- `counter` â†’ counts the lines/users
- `for (i = 1; i <= NF; i++)` â†’ loops over all fields
- `if (i == 1)` â†’ only acts on the **first field**
- `print counter " - " $i` â†’ prints counter and first field
- `break` â†’ exits the loop after processing `$1`
---

#### Example 8: String Manipulation (e.g.,Â `substr`,Â `length`)

**Goal:**Â Print the first three characters of each name and the length of their occupation.

**Shell Command (Multi-line):**

```bash
awk -F',' '
NR == 1 { next }
{
    name_prefix = substr($1, 1, 3); # Get first 3 chars of name
    occupation_len = length($4);    # Get length of occupation string
    print "Name Prefix: " name_prefix ", Occupation Length: " occupation_len
}' data.txt
```

- `substr(string, start, length)`: Extracts a substring.
- `length(string)`: Returns the length of a string.

**Output:**

```
Name Prefix: Ali, Occupation Length: 8
Name Prefix: Bob, Occupation Length: 8
Name Prefix: Cha, Occupation Length: 6
Name Prefix: Dav, Occupation Length: 8
Name Prefix: Eve, Occupation Length: 7
Name Prefix: Fra, Occupation Length: 9
```

---

#### Example 9: Replacing Text (`sub`,Â `gsub`)

**Goal:**Â Replace "New York" with "NYC" and "London" with "LDN" in the output.

**Shell Command (Multi-line):**

```bash
awk -F',' '
NR == 1 { next }
{
    line = $0; # Work on a copy of the line
    sub(/New York/, "NYC", line); # Replace first occurrence in 'line'
    gsub(/London/, "LDN", line);  # Replace all occurrences in 'line'
    print line;
}' data.txt
```

- `sub(regex, replacement, target_string)`: Replaces theÂ _first_Â occurrence ofÂ `regex`Â inÂ `target_string`. IfÂ `target_string`Â is omitted, it defaults toÂ `$0`.
- `gsub(regex, replacement, target_string)`: ReplacesÂ _all_Â occurrences ofÂ `regex`Â inÂ `target_string`. IfÂ `target_string`Â is omitted, it defaults toÂ `$0`.

**Output:**

```
Alice,30,NYC,Engineer,75000
Bob,24,LDN,Designer,60000
Charlie,35,Paris,Doctor,90000
David,29,NYC,Engineer,80000
Eve,42,LDN,Manager,110000
Frank,28,Berlin,Developer,70000
```

---

**You could see more exercises about awk here** [[awk Exercises]].